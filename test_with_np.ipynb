{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eac4cb42",
   "metadata": {},
   "source": [
    "<img src=\"AUEB.png\" /> <img src=\"MSc_BA.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda0a08",
   "metadata": {},
   "source": [
    "# Athens University of Economics and Business\n",
    "# School of Business\n",
    "# Department of Management Science & Technology\n",
    "# Master of Science in Business Analytics\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c74b6",
   "metadata": {},
   "source": [
    "<table style='float:left;font-size: 20px;'>\n",
    "    <tr>\n",
    "        <th style='text-align: left;'>Program:</th>\n",
    "        <td style='text-align: left;'>Full-Time</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style='text-align: left;'>Quarter:</th>\n",
    "        <td style='text-align: left;'>3rd (Spring Quarter)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style='text-align: left;'>Course:</th>\n",
    "        <td style='text-align: left;'>Mining Big Datasets</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th style='text-align: left;'>Assignment:</th>\n",
    "        <td style='text-align: left;'>Assignment 1</td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <th style='text-align: left;'>Students (Registration No):</th>\n",
    "        <td style='text-align: left;'>f2822202, f2822217</td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc451d77",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "## 1) Import and pre-process the dataset with users\n",
    "\n",
    "Firstly, we imported all necessary libraries:\n",
    "\n",
    "- `pandas` (imported as `pd`) for data manipulation and analysis.\n",
    "- `numpy` (imported as `np`) for numerical operations.\n",
    "- `random` for generating random numbers.\n",
    "- `IPython.display` for displaying data in a Jupyter Notebook or IPython environment.\n",
    "\n",
    "Then, we read and displayed data:\n",
    "\n",
    "- We read the contents of the \"users.txt\" file and assigned it to a variable named `users`. The file has pipe-separated values (|) and no header row. The columns are labeled as \"id\", \"age\", \"gender\", \"occupation\", and \"postcode\". Then, we displayed the `users` DataFrame. It contains 943 users with their IDs and all other included information.\n",
    "\n",
    "- We read the contents of the \"movies.txt\" file and assigned it to a variable named `movies`. The file has pipe-separated values (|) and no header row. Only the first two columns (index 0 and 1) are read and labeled as \"id\" and \"movie\". Then, we displayed the `movies` DataFrame. It contains 1,682 movies with their IDs and title.\n",
    "\n",
    "- We read the contents of the \"ratings.txt\" file and assigned it to a variable named `ratings`. The file has tab-separated values (\\t) and no header row. Only the first two columns (index 0 and 1) are read and labeled as \"userid\" and \"movieid\". Then, we displayed the `ratings` DataFrame. It contains 100,000 pairs of a single movie that a single user rated.\n",
    "\n",
    "**Note**: The files \"users.txt\", \"movies.txt\", and \"ratings.txt\", along with the \"AUEB.png\" and the \"MSc_BA.png\" (used in the first cell) must exist in the same directory as the Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcbe16c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>postcode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>85711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>writer</td>\n",
       "      <td>32067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>M</td>\n",
       "      <td>technician</td>\n",
       "      <td>43537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>33</td>\n",
       "      <td>F</td>\n",
       "      <td>other</td>\n",
       "      <td>15213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>939</td>\n",
       "      <td>26</td>\n",
       "      <td>F</td>\n",
       "      <td>student</td>\n",
       "      <td>33319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>940</td>\n",
       "      <td>32</td>\n",
       "      <td>M</td>\n",
       "      <td>administrator</td>\n",
       "      <td>02215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>941</td>\n",
       "      <td>20</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>97229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>942</td>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>librarian</td>\n",
       "      <td>78209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>943</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>student</td>\n",
       "      <td>77841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  age gender     occupation postcode\n",
       "0      1   24      M     technician    85711\n",
       "1      2   53      F          other    94043\n",
       "2      3   23      M         writer    32067\n",
       "3      4   24      M     technician    43537\n",
       "4      5   33      F          other    15213\n",
       "..   ...  ...    ...            ...      ...\n",
       "938  939   26      F        student    33319\n",
       "939  940   32      M  administrator    02215\n",
       "940  941   20      M        student    97229\n",
       "941  942   48      F      librarian    78209\n",
       "942  943   22      M        student    77841\n",
       "\n",
       "[943 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1677</th>\n",
       "      <td>1678</td>\n",
       "      <td>Mat' i syn (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1678</th>\n",
       "      <td>1679</td>\n",
       "      <td>B. Monkey (1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>1680</td>\n",
       "      <td>Sliding Doors (1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>1681</td>\n",
       "      <td>You So Crazy (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>1682</td>\n",
       "      <td>Scream of Stone (Schrei aus Stein) (1991)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1682 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                      movie\n",
       "0        1                           Toy Story (1995)\n",
       "1        2                           GoldenEye (1995)\n",
       "2        3                          Four Rooms (1995)\n",
       "3        4                          Get Shorty (1995)\n",
       "4        5                             Copycat (1995)\n",
       "...    ...                                        ...\n",
       "1677  1678                          Mat' i syn (1997)\n",
       "1678  1679                           B. Monkey (1998)\n",
       "1679  1680                       Sliding Doors (1998)\n",
       "1680  1681                        You So Crazy (1994)\n",
       "1681  1682  Scream of Stone (Schrei aus Stein) (1991)\n",
       "\n",
       "[1682 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Read and display data:\n",
    "# users\n",
    "users = pd.read_csv(\"users.txt\", sep=\"|\", header=None, names=[\"id\", \"age\", \"gender\", \"occupation\", \"postcode\"])\n",
    "display(users)\n",
    "\n",
    "# movies\n",
    "movies = pd.read_csv('movies.txt', sep='|', encoding='latin-1', usecols=[0,1], names=[\"id\",\"movie\"])\n",
    "display(movies)\n",
    "\n",
    "# ratings\n",
    "ratings = pd.read_csv(\"ratings.txt\", sep=\"\\t\", usecols=[0,1], names=[\"userid\", \"movieid\"])\n",
    "ratings\n",
    "print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c2d6b",
   "metadata": {},
   "source": [
    "## 2) Compute exact Jaccard similarity of users\n",
    "\n",
    "Firstly, we defined a class called Pair with several methods. The `Pair` class represents a pair of users, where each user is identified by `user_i` and `user_j`. The class has the following attributes:\n",
    "\n",
    "- `user_i`: Represents the identifier of the first user in the pair.\n",
    "- `user_j`: Represents the identifier of the second user in the pair.\n",
    "- `exact`: Represents the exact Jaccard similarity associated with the pair of users. It is initially set to 0.\n",
    "\n",
    "The class has the following methods:\n",
    "\n",
    "- `__init__(self, i, j)`: This is the constructor method of the `Pair` class. It is called when a new instance of the class is created. It takes two arguments, i and j, which are used to initialize the `user_i`, `user_j` and `exact` attributes of the class.\n",
    "- `set_exact(self, jac)`: This method sets the exact attribute of the `Pair` object to the exact Jaccard similarity, specified by the `jac` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2172fa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pair:\n",
    "    def __init__(self, i, j):\n",
    "        self.user_i = i\n",
    "        self.user_j = j\n",
    "        self.exact = 0\n",
    "#         self.approx=0\n",
    "        \n",
    "    def set_exact(self, jac):\n",
    "        self.exact = jac\n",
    "        \n",
    "#     def set_approx(self,aprox_jac):\n",
    "#         self.approx = aprox_jac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f9402",
   "metadata": {},
   "source": [
    "Then, we performed the following actions:\n",
    "\n",
    "1. Initialized a dictionary named `dictofpairs` to store pairs of users and their associated `Pair` object.\n",
    "2. Grouped the movie IDs that each user rated and stored the results in the `grouped` Series variable.\n",
    "3. Iterated over the index and values of the `grouped` variable to:\n",
    "    - Calculate the intersection and union of the movie IDs for each pair of users.\n",
    "    - Calculate their Jaccard similarity by dividing the intersection by the union.\n",
    "    - Create a `Pair` object using the `Pair` class and set its `exact` attribute to the calculated Jaccard similarity.\n",
    "    - Add the `Pair` object to the `dictofpairs` dictionary, using the pair of user IDs as the key and the `Pair` object as the value.\n",
    "    - Denote the pair of users that their calculated Jaccard similarity is greater than or equal to 50% and append it to the `list_exact` list.\n",
    "    - Find the most similar pair of users (the one with the highest Jaccard similarity), and\n",
    "   \n",
    "   \n",
    "4. Output the movie titles that the most similar pair rated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93c41e2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pairs of users that have similarity at least 50% are:\n",
      "1.\t(197-600) has Jaccard similarity: 0.5\n",
      "2.\t(197-826) has Jaccard similarity: 0.512987012987013\n",
      "3.\t(328-788) has Jaccard similarity: 0.6729559748427673\n",
      "4.\t(408-898) has Jaccard similarity: 0.8387096774193549\n",
      "5.\t(451-489) has Jaccard similarity: 0.5333333333333333\n",
      "6.\t(489-587) has Jaccard similarity: 0.6299212598425197\n",
      "7.\t(554-764) has Jaccard similarity: 0.5170068027210885\n",
      "8.\t(600-826) has Jaccard similarity: 0.5454545454545454\n",
      "9.\t(674-879) has Jaccard similarity: 0.5217391304347826\n",
      "10.\t(800-879) has Jaccard similarity: 0.5\n",
      "---------------------------------------------------------------------\n",
      "The most similar pair is (408-898) and their common movie titles are:\n",
      "                                  Kolya (1996)\n",
      "                                Contact (1997)\n",
      "                                Gattaca (1997)\n",
      "                      Starship Troopers (1997)\n",
      "                      Good Will Hunting (1997)\n",
      "                   English Patient, The (1996)\n",
      "                                 Scream (1996)\n",
      "                          Air Force One (1997)\n",
      "                      L.A. Confidential (1997)\n",
      "                         Rainmaker, The (1997)\n",
      "Midnight in the Garden of Good and Evil (1997)\n",
      "                                Titanic (1997)\n",
      "                              Apt Pupil (1998)\n",
      "               Everyone Says I Love You (1996)\n",
      "                           Lost Highway (1997)\n",
      "                               Cop Land (1997)\n",
      "                      Conspiracy Theory (1997)\n",
      "                                 U Turn (1997)\n",
      "                            Wag the Dog (1997)\n",
      "                                  Spawn (1997)\n",
      "                             Mouse Hunt (1997)\n",
      "                             Rocket Man (1997)\n",
      "                            Jackal, The (1997)\n",
      "                             Saint, The (1997)\n",
      "                    Tomorrow Never Dies (1997)\n",
      "                          Indian Summer (1996)\n",
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize pair of users dictionary\n",
    "dictofpairs = {}\n",
    "\n",
    "# Group movie IDs by user IDs\n",
    "grouped = ratings.groupby('userid')['movieid'].apply(set)\n",
    "\n",
    "list_exact = []\n",
    "maxJac = 0\n",
    "k = 0\n",
    "print(\"The pairs of users that have similarity at least 50% are:\")\n",
    "for i, user_i in enumerate(grouped.index[:-1]): \n",
    "    for user_j in grouped.index[i+1:]:\n",
    "        \n",
    "        # Calculate Jaccard similarity for all pairs of users\n",
    "        intersection = len(grouped[user_i] & grouped[user_j])\n",
    "        union = len(grouped[user_i] | grouped[user_j])\n",
    "        jaccard = intersection / union\n",
    "        \n",
    "        #Create pair object\n",
    "        pair = Pair(user_i,user_j)\n",
    "        pair.set_exact(jaccard)\n",
    "        dictofpairs[(user_i, user_j)] = pair # add the object to the dictionary\n",
    "        if jaccard >= 0.5:\n",
    "            k+=1\n",
    "            print(k, \".\\t(\", user_i, \"-\", user_j, \") has Jaccard similarity: \", jaccard, sep=\"\")\n",
    "            list_exact.append((user_i, user_j)) # list contains the exact similarities >= 0.5\n",
    "            if maxJac < jaccard:\n",
    "                maxJac = jaccard\n",
    "                maxPair = pair\n",
    "                # max_set contains union of movies of max simiilarity pair\n",
    "                max_set = grouped[user_i] & grouped[user_j]\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"The most similar pair is (\", maxPair.user_i, \"-\", maxPair.user_j, \") and their common movie titles are:\", sep=\"\")\n",
    "print(movies.movie.loc[movies.id.isin(max_set)].to_string(index=False))\n",
    "print(\"---------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fa97da",
   "metadata": {},
   "source": [
    "## 3) Compute similarity using Min-hash signatures\n",
    "\n",
    "Firstly, we defined two classes, `User` and `Signatures`, along with their methods. Below's an explanation of what each class and method does:\n",
    "\n",
    "1. `User` class:\n",
    "   - The `__init__` method initializes a `User` object with a `user` identifier and a `num` parameter. It also creates a NumPy array called `user_signature` with `num` elements (the number of hash functions), initialized to zero.\n",
    "\n",
    "2. `Signatures` class:\n",
    "   - The `__init__` method initializes a `Signatures` object with a `num` parameter (the number of hash functions) and an `R` parameter (R a large enough prime number). It also initializes other attributes such as `a`, `b`, and `R`, for the hash function, `combination` as a set to make sure that each hash function uses different values of a,b pairs, and `list_approx` list for storing pairs that have estimated similarity at least 50%.\n",
    "   - The `convert` method is a hash function that maps each element `x` to a value based on the hash parameters `a`, `b`, and `R`. It returns the minimum value obtained from the hash calculation i.e., the min-hash value.\n",
    "   - The `create_sig` method creates user signatures for a given `grouped` object. It initializes a list of `User` objects called `listofusers`, where each `User` object is assigned a unique identifier. It iterates `num` times and generates random hash parameters `a` and `b`. It calculates the hash values for each user in `grouped` using the `convert` method and assigns the minimum hash value to the corresponding `User` object's `user_signature` array.\n",
    "   - The `assess_similarity` method compares the user signatures of each pair of users in `listofusers`. If the similarity, defined as the ratio of matching elements in the user signatures, is greater than or equal to 0.5, the pair is added to the `list_approx`.\n",
    "   - The `LSH_similarity_evaluations` method evaluates the similarity between users using Locality Sensitive Hashing (LSH). It reshapes the user signatures 2-D array into a new 3-D array by splitting an array of (users * total number of hash functions) into (users * `bands` groups * `r` hash functions) and iterates over the pairs of users. It compares the rows of the reshaped array and if there is a match, it adds the pair to the `list_approx` and adds one to the variable `summ` responsible for counting the candidate pairs.\n",
    "   - The `calculate_false` method calculates false positives and false negatives by comparing the `list_approx` with the actual positive Pairs stored in the `list_exact` variable.\n",
    "   - The `calculate_true` method calculates true positives by comparing the `list_approx` with the forementioned `list_exact` variable.\n",
    "\n",
    "**Note**: The `LSH_similarity_evaluations` and `calculate_true`methods will be used for answering the fourth task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e289241",
   "metadata": {},
   "outputs": [],
   "source": [
    "class User:\n",
    "    \n",
    "    def __init__(self, user, num):\n",
    "        self.user = user\n",
    "        self.user_signature = np.zeros(num)    \n",
    "\n",
    "        \n",
    "class Signatures:\n",
    "    \n",
    "    def __init__(self, num, R):\n",
    "        self.num = num\n",
    "        self.a = 0\n",
    "        self.b = 0\n",
    "        self.R = R \n",
    "        self.combination = set()\n",
    "        self.list_approx=[]\n",
    "        \n",
    "    #this function is used to map each element of the series to the hash function\n",
    "    def convert(self, x):\n",
    "        return min((self.a * x + self.b) % self.R)\n",
    "\n",
    "    def create_sig(self, grouped):\n",
    "        self.listofusers = [User(i, self.num) for i in grouped.index] # initialise list\n",
    "        i = 0\n",
    "        while i < self.num:\n",
    "            self.a = random.randint(1, self.R-1)\n",
    "            self.b = random.randint(1, self.R-1)\n",
    "            if (self.a, self.b) not in self.combination:\n",
    "                self.combination.add((self.a, self.b))\n",
    "                result = grouped.map(self.convert)\n",
    "                for user_id, min_value in result.items():\n",
    "                    self.listofusers[user_id-1].user_signature[i] = min_value # Here, we assume the users go from 1-943,\n",
    "                                                                              # We could make it more dynamic if needed               \n",
    "                i += 1\n",
    "      \n",
    "    def assess_similarity(self):  \n",
    "        for i,user_i in enumerate(self.listofusers[:-1]): \n",
    "            for user_j in self.listofusers[i+1:]:\n",
    "                similarity = np.count_nonzero(user_i.user_signature==user_j.user_signature)/self.num\n",
    "                if similarity >= 0.5:\n",
    "                    self.list_approx.append((user_i.user,user_j.user)) # this list contains pairs that has >= 0.5 approx_sim.\n",
    "\n",
    "    def LSH_similarity_evaluations(self, bands):\n",
    "        r = int(self.num/bands)\n",
    "        x = np.zeros((len(self.listofusers), self.num)) \n",
    "        for i in range(len(self.listofusers)):\n",
    "            x[i] = self.listofusers[i].user_signature        \n",
    "        reshaped_arr = x.reshape(len(self.listofusers), bands, r)\n",
    "        total_eval = 0\n",
    "        summ = 0\n",
    "        for i in range(len(self.listofusers)-1):\n",
    "            for j in range(i+1,len(self.listofusers)):\n",
    "                if np.count_nonzero(np.all(reshaped_arr[i] == reshaped_arr[j], axis=1)) > 0:\n",
    "                    summ+=1\n",
    "                    self.list_approx.append((self.listofusers[i].user, self.listofusers[j].user))\n",
    "        return summ\n",
    "    \n",
    "    def calculate_false(self, list_exact):\n",
    "        #Calculate false positive\n",
    "        false_pos = 0\n",
    "        for pair in self.list_approx:\n",
    "            if pair not in list_exact:\n",
    "                false_pos+=1  \n",
    "        #Calculate false negative\n",
    "        false_neg=0\n",
    "        for pair in list_exact:\n",
    "            if pair not in self.list_approx:\n",
    "                false_neg+=1\n",
    "        return (false_pos,false_neg)\n",
    "    \n",
    "    def calculate_true(self, list_exact):\n",
    "        #Calculate true positive\n",
    "        true_pos = 0\n",
    "        for pair in self.list_approx:\n",
    "            if pair in list_exact:\n",
    "                true_pos+=1\n",
    "        return true_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6040f552",
   "metadata": {},
   "source": [
    "We then performed the following steps:\n",
    "\n",
    "1. Grouped the 'movieid' column of the `ratings` dataframe by `userid`, converted the grouped data into arrays and assigned to the variable `grouped`.\n",
    "\n",
    "2. Initialized a loop over a range of large enough prime values for the parameter `R`, greater than the number of movies, in order to finetune it.\n",
    "\n",
    "3. Inside the loop, there is another loop over a range of values for the parameter `i`, which represents the number of hash functions. The loop iterates for `i = 50`, `i = 100`, and `i = 200`.\n",
    "\n",
    "4. Within the nested loops, there is a loop that runs 5 times, represented by the variable `j`. This loop is used to calculate the average number of false positives and false negatives for each combination of `R` and `i`.\n",
    "\n",
    "5. In each iteration of the inner loop, a `Signatures` object `c` is created with `i` hash functions and `R` value. Then, the `create_sig` method is called to create user signatures based on the `grouped` data.\n",
    "\n",
    "6. The `assess_similarity` method is called to assess the similarity between users based on their min-hash signatures.\n",
    "\n",
    "7. The `calculate_false` method is used to calculate the number of false positives and false negatives by comparing the calculated similarity results (`list_approx`) with the `list_exact` list calculated in the previous question.\n",
    "\n",
    "8. The number of false positives and false negatives is accumulated over the 5 iterations of the inner loop.\n",
    "\n",
    "9. After the inner loop completes, the average number of false positives and false negatives is printed for the given `R` and `i` values.\n",
    "\n",
    "10. Finally, we checked if the sum of the average false positives and false negatives for the current `R` is smaller than the previously stored `sum_falses`. If it is, the current `R` value is assigned to `best_R`, and the `sum_falses` value is updated.\n",
    "\n",
    "11. After the outer loop completes, the value of `best_R` is printed, which represents the `R` value that resulted in the smallest sum of false positives and false negatives. \n",
    "\n",
    "For random seed 1, we found the R with the lowest average (on 5 runs) sum of false positive and negative to be 4,003 and commented out the for loop iterating over the range of prime numbers in order for the code to have a faster run time. \n",
    "\n",
    "Finally, we reached to the conclusion that increasing the number of hash functions in min-hashing tends to reduce the false positive rate but does not directly impact false negatives. The choice of the number of hash functions should be based on the desired trade-off between accuracy, computational complexity, and the acceptable false positive rate.\n",
    "\n",
    "False negatives in min-hashing depend on the similarity threshold used for identifying similar pairs of users. The number of hash functions in min-hashing affects the accuracy and false positive rate but not the false negatives. Choosing an appropriate similarity threshold is crucial for minimizing false negatives in min-hashing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3df34984",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For R: 4003\n",
      "\n",
      "Number of hash functions: 50\n",
      "Average number of false positives: 114.6\n",
      "Average number of false negatives: 2.6\n",
      "\n",
      "Number of hash functions: 100\n",
      "Average number of false positives: 62.0\n",
      "Average number of false negatives: 2.0\n",
      "\n",
      "Number of hash functions: 200\n",
      "Average number of false positives: 8.4\n",
      "Average number of false negatives: 1.0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "grouped = ratings.groupby('userid')['movieid'].apply(np.asarray)\n",
    "#Calculate average of false positive and negative\n",
    "random.seed(1)\n",
    "best_R = 0\n",
    "sum_falses = 1e+10\n",
    "for R in [4003]: # smallest number of falses = 8.4 + 1.0\n",
    "# for R in [4003, 8191, 131071, 6700417, 2147483647, 999999000001, 67280421310721]: # large prime numbers\n",
    "    print(\"For R:\", R)\n",
    "    for i in [50,100,200]:\n",
    "        false_pos=0\n",
    "        false_neg=0\n",
    "        for j in range(5):\n",
    "            c = Signatures(i,R)\n",
    "            c.create_sig(grouped)\n",
    "            c.assess_similarity()\n",
    "            pos,neg=c.calculate_false(list_exact)\n",
    "            false_pos+=pos\n",
    "            false_neg+=neg\n",
    "        print(\"\\nNumber of hash functions:\", i)\n",
    "        print(\"Average number of false positives:\", false_pos/5)\n",
    "        print(\"Average number of false negatives:\", false_neg/5)\n",
    "        if false_pos/5 + false_neg/5 < sum_falses:\n",
    "            best_R = R\n",
    "            sum_falses = false_pos/5 + false_neg/5\n",
    "    print(\"----------------------------------------\")\n",
    "# print(\"\\nThe best R is:\", best_R)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137511d1",
   "metadata": {},
   "source": [
    "## 4) Locate similar users using LSH index\n",
    "\n",
    "Firstly, we defined a function named `LSH` that performs Locality Sensitive Hashing (LSH) for approximate similarity evaluation between users. Here's a summary of what the code does:\n",
    "\n",
    "1. It takes several parameters: `num` (number of hash functions), `b` (number of bands), `R` (large prime number), `grouped` (grouped per user ratings data), and `list_exact` (exact similarity pairs).\n",
    "2. The code initializes variables for counting true positives and total similarity evaluations to zero.\n",
    "3. The code enters a loop that iterates five times to perform LSH evaluation.\n",
    "4. Within each iteration:\n",
    "   * A new instance `c` of the `Signatures` class is created with `num` and `R`.\n",
    "   * The method `create_sig` is called on `c` to create user signatures using the `grouped` ratings data.\n",
    "   * The method `LSH_similarity_evaluations` is called on `c` with `b` number of bands to find and count the number of predicted positive pairs i.e., the similarity evaluations that will be performed using the initial representations.\n",
    "   * The number of true positives is calculated using the `calculate_true` method of `c` with `list_exact`.\n",
    "   * The number of true pairs returned (true positives) and the number of candidate pairs for similarity evaluation (predicted positives) are accumulated for averaging.\n",
    "   \n",
    "   \n",
    "5. After the loop, the averages of true and predicted positives are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "483d44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSH(num, b, R, grouped, list_exact):\n",
    "    random.seed(1)\n",
    "    true_pos=0\n",
    "    sim_eval=0\n",
    "    for i in range(5):      \n",
    "        c = Signatures(num,R)\n",
    "        c.create_sig(grouped)\n",
    "        pred_pos=c.LSH_similarity_evaluations(b)\n",
    "        sim_eval+=pred_pos\n",
    "        true=c.calculate_true(list_exact)\n",
    "        true_pos+=true\n",
    "    print(\"Average number of true positives:\", true_pos/5)\n",
    "    print(\"Average number of similarity evaluations:\", sim_eval/5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae884a2",
   "metadata": {},
   "source": [
    "We then set the value of the variable `num` to 200, representing the number of hash functions to be used and with different values for bands and rows per band i.e., the specified LSH instances, we called the `LSH` function that was previously defined.\n",
    "\n",
    "From the output, we can derive that for the same number of hash functions, using LSH with more bands of less hash functions each, increases the number of true pairs returned (true positives), thus having a greater probability of capturing all of the actual positive pairs. \n",
    "\n",
    "However, using the forementioned LSH instance i.e., Instance 2 instead of the former i.e., Instance 1, produces more candidate pairs (predicted positive) for assesing their true similarity using their initial representations, thus also increasing the pairs predicted falsely as similar (false positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0875aeaa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of hash functions is: 200\n",
      "--------------------------------\n",
      "| LSH Instance: 1 \t\t|\n",
      "| Bands: 25 \t\t\t|\n",
      "| Hash functions per band: 8 \t|\n",
      "--------------------------------\n",
      "\n",
      "Average number of true positives: 3.8\n",
      "Average number of similarity evaluations: 51.6\n",
      "\n",
      "--------------------------------\n",
      "| LSH Instance: 2 \t\t|\n",
      "| Bands: 40 \t\t\t|\n",
      "| Hash functions per band: 5 \t|\n",
      "--------------------------------\n",
      "\n",
      "Average number of true positives: 9.0\n",
      "Average number of similarity evaluations: 2244.6\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num = 200\n",
    "print(\"The number of hash functions is:\", num)\n",
    "print('--------------------------------')\n",
    "print(\"| LSH Instance: 1 \\t\\t|\")\n",
    "b = 25\n",
    "r = 8\n",
    "print(\"| Bands:\", b, \"\\t\\t\\t|\")\n",
    "print(\"| Hash functions per band:\", r, \"\\t|\")\n",
    "print('--------------------------------')\n",
    "print(\"\")\n",
    "LSH(num, b, best_R, grouped, list_exact)\n",
    "print(\"\")\n",
    "print('--------------------------------')\n",
    "print(\"| LSH Instance: 2 \\t\\t|\")\n",
    "b = 40\n",
    "r = 5\n",
    "print(\"| Bands:\", b, \"\\t\\t\\t|\")\n",
    "print(\"| Hash functions per band:\", r, \"\\t|\")\n",
    "print('--------------------------------')\n",
    "print(\"\")\n",
    "LSH(num, b, best_R, grouped, list_exact)\n",
    "print(\"-------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2069d4ce",
   "metadata": {},
   "source": [
    "Using LSH (Locality Sensitive Hashing), instead of directly comparing users on their true representations, offers a trade-off between accuracy and efficiency. Here are the gains and losses associated with using LSH:\n",
    "\n",
    "Gains:\n",
    "1. Efficiency: LSH allows for efficient similarity evaluation by reducing the number of pairwise comparisons required. It achieves this by using hash functions to group similar items together, allowing for faster identification of potential matches. As we reported above, even on the latter case that the number of similarity evaluations increased, it never reached the total number of similarity evaluations performed using the initial representations which is 444,153 (943*942/2).\n",
    "2. Scalability: LSH is particularly beneficial in scenarios with large datasets and high-dimensional data. It significantly reduces the computational burden compared to direct pairwise comparisons, making it more scalable for large-scale applications.\n",
    "3. Reduced Memory Usage: LSH typically requires storing only the compact hash signatures of the items rather than their full representations. This leads to lower memory requirements, which can be advantageous when dealing with memory-constrained systems.\n",
    "\n",
    "Losses:\n",
    "1. Approximation: LSH introduces an element of approximation. It may classify some dissimilar pairs as similar (false positives) or fail to identify some similar pairs (false negatives). The degree of approximation depends on the chosen parameters and the nature of the data. Therefore, LSH is not guaranteed to provide exact similarity results. As we reported above, even on the latter case that the number of true positive pairs increased, it did not reach the actual number of true pairs which is 10.\n",
    "2. Quality of Similarity: The similarity measured through LSH is often a proximity measure rather than an exact representation. It relies on the choice of hash functions and the number of hash tables used, which can impact the quality of similarity assessments. This may lead to slightly different similarity rankings compared to the true representations.\n",
    "3. Sensitivity to Parameters: LSH performance is influenced by the selection of parameters such as the number of hash functions and the number of bands and thus it involves a trade-off. As we reported previously, as we were increasing the bands, true positives were increasing, but the same happened to the false positives too (number of similarity evaluations minus the true positives). Thus, choosing inappropriate parameters can result in decreased accuracy or efficiency. \n",
    "\n",
    "In summary, LSH offers significant gains in terms of computational efficiency and scalability compared to direct comparisons. However, it introduces an approximation factor and may yield slightly different similarity results. The suitability of LSH depends on the specific application requirements, the acceptable trade-off between accuracy and efficiency, and the characteristics of the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
